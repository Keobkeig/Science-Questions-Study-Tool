{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import genesis\n",
    "genesis_ic = wn.ic(genesis, False, 0.0)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings \n",
    "from sklearn.neighbors import KNeighborsClassifier as KNC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A few things. You might have negative- frequen...</td>\n",
       "      <td>Biology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Is it so hard to believe that there exist part...</td>\n",
       "      <td>Physics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>There are bees</td>\n",
       "      <td>Biology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm a medication technician. And that's alot o...</td>\n",
       "      <td>Biology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cesium is such a pretty metal.</td>\n",
       "      <td>Chemistry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8690</th>\n",
       "      <td>I make similar observations over the last week...</td>\n",
       "      <td>Biology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8691</th>\n",
       "      <td>You would know.</td>\n",
       "      <td>Biology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8692</th>\n",
       "      <td>Also use the correct number of sig figs</td>\n",
       "      <td>Chemistry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8693</th>\n",
       "      <td>What about the ethical delimmas,  groundbreaki...</td>\n",
       "      <td>Biology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8694</th>\n",
       "      <td>I would like to know too.</td>\n",
       "      <td>Biology</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8695 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Comment      Topic\n",
       "0     A few things. You might have negative- frequen...    Biology\n",
       "1     Is it so hard to believe that there exist part...    Physics\n",
       "2                                        There are bees    Biology\n",
       "3     I'm a medication technician. And that's alot o...    Biology\n",
       "4                        Cesium is such a pretty metal.  Chemistry\n",
       "...                                                 ...        ...\n",
       "8690  I make similar observations over the last week...    Biology\n",
       "8691                                    You would know.    Biology\n",
       "8692            Also use the correct number of sig figs  Chemistry\n",
       "8693  What about the ethical delimmas,  groundbreaki...    Biology\n",
       "8694                          I would like to know too.    Biology\n",
       "\n",
       "[8695 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "data.drop('Id', axis=1 , inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "CommentsToBeTokenized = data['Comment'] \n",
    "tfidf_result=tfidf.fit_transform(CommentsToBeTokenized).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features= 6000)\n",
    "tfidf_result = vectorizer.fit_transform(CommentsToBeTokenized).toarray()\n",
    "features = vectorizer.get_feature_names_out()\n",
    "tfidf_result = pd.DataFrame(tfidf_result, columns=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\serap\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Biology       0.81      0.36      0.50       707\n",
      "   Chemistry       0.39      0.88      0.54       576\n",
      "     Physics       0.62      0.17      0.27       456\n",
      "\n",
      "    accuracy                           0.48      1739\n",
      "   macro avg       0.61      0.47      0.44      1739\n",
      "weighted avg       0.62      0.48      0.45      1739\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\serap\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Biology       0.44      0.96      0.60       707\n",
      "   Chemistry       0.49      0.13      0.21       576\n",
      "     Physics       0.95      0.08      0.15       456\n",
      "\n",
      "    accuracy                           0.45      1739\n",
      "   macro avg       0.63      0.39      0.32      1739\n",
      "weighted avg       0.59      0.45      0.35      1739\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\serap\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Biology       0.71      0.38      0.49       707\n",
      "   Chemistry       0.39      0.89      0.55       576\n",
      "     Physics       0.75      0.09      0.15       456\n",
      "\n",
      "    accuracy                           0.47      1739\n",
      "   macro avg       0.62      0.45      0.40      1739\n",
      "weighted avg       0.62      0.47      0.42      1739\n",
      "\n",
      "\n",
      "Testing Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Biology       0.60      0.26      0.36       707\n",
      "   Chemistry       0.36      0.62      0.45       576\n",
      "     Physics       0.32      0.31      0.32       456\n",
      "\n",
      "    accuracy                           0.39      1739\n",
      "   macro avg       0.43      0.40      0.38      1739\n",
      "weighted avg       0.45      0.39      0.38      1739\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\serap\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(tfidf_result, data['Topic'], test_size= 0.2)\n",
    "for k in range(1,5):\n",
    "    model = KNC(n_neighbors= k )\n",
    "    model.fit(x_train, y_train)\n",
    "    y_predicted = model.predict(x_test)\n",
    "    print(\"\\nTesting Results:\\n\")\n",
    "    print(classification_report(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN_NLC_Classifer():\n",
    "    def __init__(self, k=1, distance_type = 'path'):\n",
    "        self.k = k\n",
    "        self.distance_type = distance_type\n",
    "\n",
    "    # This function is used for training\n",
    "    def fit(self, x_train, y_train):\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "\n",
    "    # This function runs the K(1) nearest neighbour algorithm and\n",
    "    # returns the label with closest match. \n",
    "    def predict(self, x_test):\n",
    "        self.x_test = x_test\n",
    "        y_predict = []\n",
    "\n",
    "        for i in range(len(x_test)):\n",
    "            max_sim = 0\n",
    "            max_index = 0\n",
    "            for j in range(self.x_train.shape[0]):\n",
    "                temp = self.document_similarity(x_test[i], self.x_train[j])\n",
    "                if temp > max_sim:\n",
    "                    max_sim = temp\n",
    "                    max_index = j\n",
    "            y_predict.append(self.y_train[max_index])\n",
    "        return y_predict\n",
    "    \n",
    "    def convert_tag(self, tag):\n",
    "        \"\"\"Convert the tag given by nltk.pos_tag to the tag used by wordnet.synsets\"\"\"\n",
    "        tag_dict = {'N': 'n', 'J': 'a', 'R': 'r', 'V': 'v'}\n",
    "        try:\n",
    "            return tag_dict[tag[0]]\n",
    "        except KeyError:\n",
    "            return None\n",
    "\n",
    "\n",
    "    def doc_to_synsets(self, doc):\n",
    "        \"\"\"\n",
    "            Returns a list of synsets in document.\n",
    "            Tokenizes and tags the words in the document doc.\n",
    "            Then finds the first synset for each word/tag combination.\n",
    "        If a synset is not found for that combination it is skipped.\n",
    "\n",
    "        Args:\n",
    "            doc: string to be converted\n",
    "\n",
    "        Returns:\n",
    "            list of synsets\n",
    "        \"\"\"\n",
    "        tokens = word_tokenize(doc+' ')\n",
    "        \n",
    "        l = []\n",
    "        tags = nltk.pos_tag([tokens[0] + ' ']) if len(tokens) == 1 else nltk.pos_tag(tokens)\n",
    "        \n",
    "        for token, tag in zip(tokens, tags):\n",
    "            syntag = self.convert_tag(tag[1])\n",
    "            syns = wn.synsets(token, syntag)\n",
    "            if (len(syns) > 0):\n",
    "                l.append(syns[0])\n",
    "        return l  \n",
    "    def similarity_score(self, s1, s2, distance_type = 'path'):\n",
    "        \"\"\"\n",
    "          Calculate the normalized similarity score of s1 onto s2\n",
    "          For each synset in s1, finds the synset in s2 with the largest similarity value.\n",
    "          Sum of all of the largest similarity values and normalize this value by dividing it by the\n",
    "          number of largest similarity values found.\n",
    "\n",
    "          Args:\n",
    "              s1, s2: list of synsets from doc_to_synsets\n",
    "\n",
    "          Returns:\n",
    "              normalized similarity score of s1 onto s2\n",
    "          \"\"\"\n",
    "        s1_largest_scores = []\n",
    "\n",
    "        for i, s1_synset in enumerate(s1, 0):\n",
    "            max_score = 0\n",
    "            for s2_synset in s2:\n",
    "                if distance_type == 'path':\n",
    "                    score = s1_synset.path_similarity(s2_synset, simulate_root = False)\n",
    "                else:\n",
    "                    score = s1_synset.wup_similarity(s2_synset)                  \n",
    "                    if score != None:\n",
    "                        if score > max_score:\n",
    "                            max_score = score\n",
    "              \n",
    "                    if max_score != 0:\n",
    "                        s1_largest_scores.append(max_score)\n",
    "          \n",
    "        mean_score = np.mean(s1_largest_scores)\n",
    "                 \n",
    "        return mean_score  \n",
    "    def document_similarity(self,doc1, doc2):\n",
    "        synsets1 = self.doc_to_synsets(doc1)\n",
    "        synsets2 = self.doc_to_synsets(doc2)\n",
    "          \n",
    "        return (self.similarity_score(synsets1, synsets2) + self.similarity_score(synsets2, synsets1)) / 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is the sample of training text after removing the stop words\n",
      "0    thing might negative frequency dependent selec...\n",
      "1    hard believe exist particular detect anything ...\n",
      "2                                                  bee\n",
      "3    medication technician alot drug liver probably...\n",
      "4                                  cesium pretty metal\n",
      "5                               meant question unclear\n",
      "6                                 shove as see happens\n",
      "7    mean butter besides sugar baking soda peanut yeah\n",
      "8                         http joinchat gellhlumcxhngi\n",
      "9    well thing really induce immune response intro...\n",
      "Name: Comment, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "s = stopwords.words('english')\n",
    "ps = nltk.wordnet.WordNetLemmatizer()\n",
    "for i in range(data.shape[0]):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', data.loc[i,'Comment'])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = [ps.lemmatize(word) for word in review if not word in s]\n",
    "    review = ' '.join(review)\n",
    "    data.loc[i, 'Comment'] = review\n",
    "X_train = data['Comment']\n",
    "y_train = data['Topic']\n",
    "print(\"Below is the sample of training text after removing the stop words\")\n",
    "print(data['Comment'][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\serap\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\serap\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "classifier = KNN_NLC_Classifer(k=1, distance_type='path')\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "final_test_list = ['will it rain', 'Is it hot outside?' , 'What is the expected high for today?' , \n",
    "                   'Will it be foggy tomorrow?', 'Should I prepare for sleet?',\n",
    "                     'Will there be a storm today?', 'do we need to take umbrella today',\n",
    "                    'will it be wet tomorrow', 'is it humid tomorrow', 'what is the precipitation today',\n",
    "                    'is it freezing outside', 'is it cool outside', \"are there strong winds outside\",]\n",
    "                 \n",
    "test_corpus = []\n",
    "for i in range(len(final_test_list)):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', final_test_list[i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "\n",
    "    review = [ps.lemmatize(word) for word in review if not word in s]\n",
    "    review = ' '.join(review)\n",
    "    test_corpus.append(review)\n",
    "\n",
    "y_pred_final = classifier.predict(test_corpus)\n",
    "\n",
    "output_df = pd.DataFrame(data = {'text': final_test_list, 'code': y_pred_final})\n",
    "output_df['answer'] = np.where(output_df['code']==1, 'Temperature','Conditions')\n",
    "print(output_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
